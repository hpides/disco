{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "RUN_RE = re.compile(r\"Running ((.*) intermediates, )?(\\d+) child.*, (\\d+) stream.*\")\n",
    "THROUGHPUT_RE = re.compile(r\"Found sustainable candidate \\((\\d+) events/s.\\)*\")\n",
    "BENCHMARK_RE = re.compile(r\"BENCHMARK: WINDOWS: (.*) - AGG_FNS: (\\w+)( - (DISTRIBUTED|SINGLE_NODE))?\")\n",
    "\n",
    "def parse_log_file(log_file):\n",
    "    sustainable_throughputs = {}\n",
    "    \n",
    "    current_bm = None\n",
    "    current_run = None\n",
    "    current_throughput = None\n",
    "    with open(log_file) as f:\n",
    "        for line in f:\n",
    "            benchmark_match = BENCHMARK_RE.match(line)\n",
    "            if benchmark_match is not None:\n",
    "                curr_windows, curr_agg_fn = benchmark_match.group(1), benchmark_match.group(2)\n",
    "                curr_mode = benchmark_match.group(4)\n",
    "                curr_mode = curr_mode if curr_mode is not None else \"DISTRIBUTED\"\n",
    "                current_bm = (curr_windows, curr_agg_fn, curr_mode)\n",
    "                sustainable_throughputs[current_bm] = {}\n",
    "                current_throughput = None\n",
    "                # print(current_bm)\n",
    "            \n",
    "            run_match = RUN_RE.match(line)\n",
    "            if run_match is not None:\n",
    "                if current_run != None:\n",
    "                    print(f\"Did not find candidate line for {current_run}\")\n",
    "                current_run = (int(run_match.group(3)), int(run_match.group(4)))\n",
    "                current_throughput = None\n",
    "                # print(current_run)\n",
    "\n",
    "            throughput_match = THROUGHPUT_RE.match(line)\n",
    "            if throughput_match is not None:\n",
    "                if current_throughput is not None:\n",
    "                    print(f\"Did not find run line after {current_run}\")\n",
    "                current_throughput = int(throughput_match.group(1))\n",
    "                sustainable_throughputs[current_bm][current_run] = current_throughput\n",
    "                current_run = None\n",
    "                \n",
    "    if current_run is not None:\n",
    "        print(f\"Did not find candidate line for {current_run}\")\n",
    "                \n",
    "    return sustainable_throughputs\n",
    "                \n",
    "def get_all_throughputs(log_path):\n",
    "    all_throughputs = defaultdict(dict)\n",
    "    for log_file in sorted(os.listdir(log_path)):\n",
    "        if log_file.endswith(\".log\"):\n",
    "            print(f\"Parsing {log_file}\")\n",
    "            sustainable_throughputs = parse_log_file(os.path.join(log_path, log_file))\n",
    "#             print(f\"current: {sustainable_throughputs}\")\n",
    "            for bm, tps in sustainable_throughputs.items():\n",
    "                all_throughputs[bm].update(tps)\n",
    "#             print(f\"all:     {all_throughputs}\\n\")\n",
    "    return all_throughputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BASE_LOG_DIR = \"/Users/law/repos/ma/benchmark-runs\"\n",
    "\n",
    "def merge_paths(paths):\n",
    "    merged_tp = defaultdict(dict)\n",
    "    for path in paths:\n",
    "        abs_path = os.path.join(BASE_LOG_DIR, path)\n",
    "        tp = get_all_throughputs(abs_path)\n",
    "        for bm, tps in tp.items():\n",
    "            merged_tp[bm].update(tps)\n",
    "    pprint.pprint(merged_tp)\n",
    "    return merged_tp\n",
    "\n",
    "print(\"CONCURRENT\")\n",
    "CONCURRENT_PATHS = [\n",
    "    \"concurrent_tumbling_20\"\n",
    "]\n",
    "CONCURRENT_TP = merge_paths(CONCURRENT_PATHS)\n",
    " \n",
    "print(\"MATRIX\")\n",
    "MATRIX_PATHS = [\n",
    "    \"matrix_dist_all\",\n",
    "    \"matrix_single_all\",\n",
    "]\n",
    "MATRIX_TP = merge_paths(MATRIX_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_throughputs(all_throughputs):\n",
    "    for benchmark, run_throughputs in sorted(all_throughputs.items()):\n",
    "        print(f\"Benchmark {benchmark}\")\n",
    "        for (num_children, num_streams), throughput in sorted(run_throughputs.items()):\n",
    "            print(f\"Total sustainable throughput for {num_children} child(ren) with \" \\\n",
    "                  f\"{num_streams // num_children} stream(s) each \" \\\n",
    "                  f\"is {(throughput * num_streams // num_children): >7d} events/s per child.\")\n",
    "        print()\n",
    "    \n",
    "\n",
    "print_throughputs(CONCURRENT_TP)\n",
    "print_throughputs(MATRIX_TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "rcParams.update({'figure.autolayout': True, 'pgf.rcfonts' : False, 'font.size': 14, 'lines.linewidth': 3})\n",
    "plt.style.use('seaborn-deep')\n",
    "FORMATS = [\"b-o\", \"g--x\", \"r-^\", \"c-<\", \"m-+\", \"k-*\",]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Sustainable Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_throughput_group(child_streams, throughputs, title):\n",
    "    formats = iter(FORMATS)\n",
    "    sorted_throughputs = sorted(throughputs.items())\n",
    "    print(f\"sorted_tps: {sorted_throughputs}\")\n",
    "    for agg_fn, tp in sorted_throughputs:\n",
    "        plt.plot(tp, next(formats), label=agg_fn)\n",
    "        \n",
    "    plt.legend()\n",
    "    str_child_streams = [str(cs) for cs in child_streams]\n",
    "    plt.xticks(range(len(child_streams)), str_child_streams)\n",
    "    plt.ylabel(\"events/s in mio.\")\n",
    "    plt.xlabel(\"#children, # streams\")\n",
    "    plt.title(title)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.show()\n",
    "#     plt.savefig(f\"/tmp/plots/single_child_{title[0].replace(',', '_')}_{title[1]}.png\")\n",
    "#     plt.close()\n",
    "\n",
    "def group_throughput_mode(bms, num_child_streams):\n",
    "    groups = defaultdict(dict)\n",
    "    for benchmark, run_throughputs in bms:\n",
    "        group, agg_fn, mode = benchmark\n",
    "        group_key = (group, mode)\n",
    "        print(f\"Adding benchmark {benchmark} to group {group_key}\")\n",
    "        bm_throughputs = []\n",
    "        for num_cs in num_child_streams:\n",
    "            num_streams = num_cs[1] \n",
    "            throughput = run_throughputs[num_cs]\n",
    "            bm_throughputs.append((num_streams * throughput) / 1_000_000)\n",
    "        groups[group_key][agg_fn] = bm_throughputs\n",
    "    return groups\n",
    "    \n",
    "def group_throughput_benchmarks(bms, num_child_streams):\n",
    "    all_groups = group_throughput_mode(sorted(bms.items()), num_child_streams)\n",
    "    \n",
    "    groups = {}\n",
    "    groups[\"distributed\"] = {run: tps for run, tps in all_groups.items() if run[1] == \"DISTRIBUTED\"}\n",
    "    groups[\"centralized\"] = {run: tps for run, tps in all_groups.items() if run[1] == \"SINGLE_NODE\"}\n",
    "    \n",
    "#     print(\"\\n\\n\")\n",
    "#     print(f\"NODE_CONFIG: {num_child_streams}\")\n",
    "#     print(\"\\nGROUPS:\")\n",
    "#     pprint.pprint(groups)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_throughput_benchmarks(bms, num_child_streams):\n",
    "    groups = group_throughput_benchmarks(bms, num_child_streams)\n",
    "    for mode, sub_groups in groups.items():\n",
    "        for group, throughputs in sub_groups.items():\n",
    "            plot_throughput_group(num_child_streams, throughputs, group)\n",
    "        \n",
    "def plot_multi_child_throughputs(bms):\n",
    "    num_child_streams = [(1, 1), (2, 2), (4, 4), (8, 8)]\n",
    "    plot_throughput_benchmarks(bms, num_child_streams)\n",
    "    \n",
    "def plot_single_child_throughputs(bms):\n",
    "    num_child_streams = [(1, 1), (1, 2), (1, 4), (1, 8)]\n",
    "    plot_throughput_benchmarks(bms, num_child_streams)\n",
    "\n",
    "           \n",
    "plot_single_child_throughputs(MATRIX_TP)\n",
    "plot_multi_child_throughputs(MATRIX_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_throughput_by_agg_fn(child_streams, throughputs):\n",
    "    print(throughputs)\n",
    "    formats = iter(FORMATS)\n",
    "    data = defaultdict(list)\n",
    "    for mode, run in sorted(throughputs):\n",
    "        for agg_fn, tps in run.items():\n",
    "            data[agg_fn].append(tps)\n",
    "\n",
    "    print(data)\n",
    "#     dist_format = next(formats)\n",
    "#     single_format = next(formats)\n",
    "    for agg_fn, (dist, single) in data.items():\n",
    "        if agg_fn != \"MAX\": continue\n",
    "        plt.plot([1, 2, 4, 8], dist, label=\"distributed max\", marker=\"o\", ms=7)\n",
    "        plt.plot([1, 2, 4, 8], single, label=\"centralized max\", marker=\"^\", ms=8)\n",
    "#         plt.plot([1, 2, 4, 8], 4 * [1.036601], label=\"max throughput\", ls=\"--\")\n",
    "        plt.legend()\n",
    "#         str_child_streams = [str(cs[0]) for cs in child_streams]\n",
    "#         plt.xticks(range(8))\n",
    "        plt.ylabel(\"events/s in mio.\")\n",
    "        plt.xlabel(\"# input streams\")\n",
    "#         plt.title(agg_fn)\n",
    "        plt.ylim(ymin=0, ymax=1.1 * max(dist))\n",
    "        plt.xlim(xmin=0.5)\n",
    "        plt.savefig(f\"/tmp/plots/tumbling_single_node_{agg_fn}.png\")\n",
    "        plt.savefig(f\"/tmp/plots/tumbling_single_node_{agg_fn}.pdf\")\n",
    "        plt.show()\n",
    "\n",
    "def plot_tumbling_scale(bms):\n",
    "    num_child_streams = [(1, 1), (2, 2), (4, 4), (8, 8)]\n",
    "    groups = group_throughput_benchmarks(bms, num_child_streams)\n",
    "    groups = [(bm[1], tps) for mode, g in groups.items() for bm, tps in g.items() if bm[0].startswith(\"TUMBLING\")]\n",
    "    plot_throughput_by_agg_fn(num_child_streams, groups)\n",
    "    \n",
    "def plot_tumbling_single_node(bms):\n",
    "    num_child_streams = [(1, 1), (1, 2), (1, 4), (1, 8)]\n",
    "    groups = group_throughput_benchmarks(bms, num_child_streams)\n",
    "    groups = [(bm[1], tps) for mode, g in groups.items() for bm, tps in g.items() if bm[0].startswith(\"TUMBLING\")]\n",
    "    plot_throughput_by_agg_fn(num_child_streams, groups)\n",
    "    \n",
    "\n",
    "# plot_tumbling_scale(MATRIX_TP)\n",
    "plot_tumbling_single_node(MATRIX_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_concurrent_throughput_group(num_windows, throughputs):\n",
    "    markers = iter(['o', '^', 'x', '*'])\n",
    "    print(throughputs)\n",
    "    for (agg_fn, mode), tps in sorted(throughputs):\n",
    "        if agg_fn == \"M_MEDIAN\": continue\n",
    "        mode_str = \"distributed\" if mode == \"DISTRIBUTED\" else \"centralized\"\n",
    "        plt.plot(num_windows, tps, marker=next(markers), ms=8, label=f\"{mode_str} - {agg_fn.replace('M_', '').lower()}\")\n",
    "\n",
    "    plt.ylabel(\"events/s in mio.\")\n",
    "    plt.xlabel(\"# concurrent windows\")\n",
    "    plt.legend()\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.savefig(f\"/tmp/plots/concurrent_decomposable.png\")\n",
    "    plt.savefig(f\"/tmp/plots/concurrent_decomposable.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "bm_throughputs = defaultdict(list)\n",
    "bm_num_windows = set()\n",
    "for benchmark, run_throughputs in sorted(CONCURRENT_TP.items(), key=lambda x: int(x[0][0].split(\",\")[1])):\n",
    "    print(f\"Benchmark {benchmark}\")\n",
    "    num_windows = int(benchmark[0].split(\",\")[1])\n",
    "    bm_num_windows.add(num_windows)\n",
    "    agg_fn = benchmark[1]\n",
    "    mode = benchmark[2]\n",
    "    for throughput in run_throughputs.values(): \n",
    "        bm_throughputs[(agg_fn, mode)].append(throughput / 1_000_000)\n",
    "\n",
    "# print(bm_throughputs)\n",
    "\n",
    "plot_concurrent_throughput_group(sorted(bm_num_windows), bm_throughputs.items())\n",
    "\n",
    "# for (agg_fn, mode), tps in sorted(bm_throughputs.items()):\n",
    "#     plot_concurrent_throughput_group(sorted(bm_num_windows), (agg_fn.replace('M_', '').lower(), mode, tps), f\"{agg_fn.replace('M_', '')} - {mode}\")\n",
    "    # plt.savefig(f\"/tmp/plots/concurrent_max_tumbling.png\")\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
