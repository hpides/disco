{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "RUN_RE = re.compile(r\"Running ((.*) intermediates, )?(\\d+) child.*, (\\d+) stream.*\")\n",
    "THROUGHPUT_RE = re.compile(r\"Found sustainable candidate \\((\\d+) events/s.\\)*\")\n",
    "BENCHMARK_RE = re.compile(r\"BENCHMARK: WINDOWS: (.*) - AGG_FNS: (\\w+)( - (DISTRIBUTED|SINGLE_NODE))?\")\n",
    "NUM_KEYS_RE = re.compile(r\"BM NUM_KEYS: (\\d+)\")\n",
    "\n",
    "def parse_log_file(log_file):\n",
    "    sustainable_throughputs = {}\n",
    "    \n",
    "    current_bm = None\n",
    "    current_run = None\n",
    "    current_throughput = None\n",
    "    has_keys = False\n",
    "    with open(log_file) as f:\n",
    "        for line in f:\n",
    "            benchmark_match = BENCHMARK_RE.match(line)\n",
    "            if benchmark_match is not None:\n",
    "                curr_windows, curr_agg_fn = benchmark_match.group(1), benchmark_match.group(2)\n",
    "                curr_mode = benchmark_match.group(4)\n",
    "                curr_mode = curr_mode if curr_mode is not None else \"DISTRIBUTED\"\n",
    "                current_bm = (curr_windows, curr_agg_fn, curr_mode)\n",
    "                if current_bm not in sustainable_throughputs:\n",
    "                    sustainable_throughputs[current_bm] = {}\n",
    "                current_throughput = None\n",
    "                # print(current_bm)\n",
    "            \n",
    "            run_match = RUN_RE.match(line)\n",
    "            if run_match is not None:\n",
    "                if has_keys: continue\n",
    "                if current_run != None:\n",
    "                    print(f\"Did not find candidate line for {current_run}\")\n",
    "                current_run = (int(run_match.group(3)), int(run_match.group(4)))\n",
    "                current_throughput = None\n",
    "                # print(current_run)\n",
    "            \n",
    "            keys_match = NUM_KEYS_RE.match(line)\n",
    "            if keys_match is not None:\n",
    "                has_keys = True\n",
    "                num_keys = int(keys_match.group(1))\n",
    "                current_run = (1, num_keys)\n",
    "\n",
    "            throughput_match = THROUGHPUT_RE.match(line)\n",
    "            if throughput_match is not None:\n",
    "                if current_throughput is not None:\n",
    "                    print(f\"Did not find run line after {current_run}\")\n",
    "                current_throughput = int(throughput_match.group(1))\n",
    "                sustainable_throughputs[current_bm][current_run] = current_throughput\n",
    "                current_run = None\n",
    "                \n",
    "    if current_run is not None:\n",
    "        print(f\"Did not find candidate line for {current_run}\")\n",
    "                \n",
    "    return sustainable_throughputs\n",
    "                \n",
    "def get_all_throughputs(log_path):\n",
    "    all_throughputs = defaultdict(dict)\n",
    "    for log_file in sorted(os.listdir(log_path)):\n",
    "        if log_file.endswith(\".log\"):\n",
    "            print(f\"Parsing {log_file}\")\n",
    "            sustainable_throughputs = parse_log_file(os.path.join(log_path, log_file))\n",
    "#             print(f\"current: {sustainable_throughputs}\")\n",
    "            for bm, tps in sustainable_throughputs.items():\n",
    "                all_throughputs[bm].update(tps)\n",
    "#             print(f\"all:     {all_throughputs}\\n\")\n",
    "    return all_throughputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BASE_LOG_DIR = \"/Users/law/repos/ma/benchmark-runs\"\n",
    "\n",
    "def merge_paths(paths):\n",
    "    merged_tp = defaultdict(dict)\n",
    "    for path in paths:\n",
    "        abs_path = os.path.join(BASE_LOG_DIR, path)\n",
    "        tp = get_all_throughputs(abs_path)\n",
    "        for bm, tps in tp.items():\n",
    "            merged_tp[bm].update(tps)\n",
    "    pprint.pprint(merged_tp)\n",
    "    return merged_tp\n",
    "\n",
    "print(\"CONCURRENT\")\n",
    "CONCURRENT_PATHS = [\n",
    "    \"concurrent_tumbling_20\"\n",
    "]\n",
    "CONCURRENT_TP = merge_paths(CONCURRENT_PATHS)\n",
    " \n",
    "print(\"MATRIX\")\n",
    "MATRIX_PATHS = [\n",
    "    \"matrix_dist_all\",\n",
    "    \"matrix_single_all\",\n",
    "]\n",
    "MATRIX_TP = merge_paths(MATRIX_PATHS)\n",
    "\n",
    "print(\"COUNT\")\n",
    "COUNT_PATHS = [\n",
    "    \"count_window\",\n",
    "]\n",
    "COUNT_TP = merge_paths(COUNT_PATHS)\n",
    "\n",
    "print(\"ROOT\")\n",
    "ROOT_PATHS = [\n",
    "    \"root_tp\",\n",
    "]\n",
    "ROOT_TP = merge_paths(ROOT_PATHS)\n",
    "\n",
    "print(\"NUM KEYS\")\n",
    "KEYS_PATHS = [\n",
    "    \"num_keys\",\n",
    "]\n",
    "KEYS_TP = merge_paths(KEYS_PATHS)\n",
    "\n",
    "print(\"SESSIONS\")\n",
    "SESSION_PATHS = [\n",
    "    \"sessions\",\n",
    "]\n",
    "SESSION_TP = merge_paths(SESSION_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_throughputs(all_throughputs):\n",
    "    for benchmark, run_throughputs in sorted(all_throughputs.items()):\n",
    "        print(f\"Benchmark {benchmark}\")\n",
    "        for (num_children, num_streams), throughput in sorted(run_throughputs.items()):\n",
    "            print(f\"Total sustainable throughput for {num_children} child(ren) with \" \\\n",
    "                  f\"{num_streams // num_children} stream(s) each \" \\\n",
    "                  f\"is {(throughput * num_streams // num_children): >7d} events/s per child.\")\n",
    "        print()\n",
    "    \n",
    "\n",
    "print_throughputs(CONCURRENT_TP)\n",
    "print_throughputs(MATRIX_TP)\n",
    "print_throughputs(COUNT_TP)\n",
    "print_throughputs(ROOT_TP)\n",
    "print_throughputs(SESSION_TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "rcParams.update({'figure.autolayout': True, 'pgf.rcfonts' : False, 'font.size': 14, 'lines.linewidth': 3})\n",
    "plt.style.use('seaborn-deep')\n",
    "FORMATS = [\"b-o\", \"g--x\", \"r-^\", \"c-<\", \"m-+\", \"k-*\",]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Sustainable Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_throughput_group(child_streams, throughputs, title):\n",
    "    markers = iter([\"x\", \"^\", \"o\"])\n",
    "    sorted_throughputs = sorted(throughputs.items())\n",
    "    print(f\"sorted_tps: {sorted_throughputs}\")   \n",
    "    \n",
    "#     f, (ax, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "    \n",
    "    for agg_fn, tp in sorted_throughputs:\n",
    "        m = next(markers)\n",
    "#         if agg_fn == \"M_MEDIAN\": \n",
    "#         plt.plot([1, 2, 4, 8], tp, marker=m, label=agg_fn.replace(\"M_\", \"\").lower())\n",
    "        plt.plot([1, 10, 100, 1000, 10000, 100000], tp, marker=m, label=agg_fn.replace(\"M_\", \"\").lower())\n",
    "        #ax2.plot([1, 2, 4, 8, 16], tp, marker=m, label=agg_fn.replace(\"M_\", \"\").lower())\n",
    "        \n",
    "# Gap plot\n",
    "#     ax.set_ylim(50, 250)  # outliers only\n",
    "#     ax2.set_ylim(0, 5.5)  # most of the data\n",
    "\n",
    "#     ax.spines['bottom'].set_visible(False)\n",
    "#     ax2.spines['top'].set_visible(False)\n",
    "#     ax.xaxis.set_ticks_position('none') \n",
    "#     ax.tick_params(labeltop='off')  # don't put tick labels at the top\n",
    "\n",
    "#     d = .015  # how big to make the diagonal lines in axes coordinates\n",
    "#     kwargs = dict(transform=ax.transAxes, color='k', clip_on=False)\n",
    "#     ax.plot((-d, +d), (-d, +d), **kwargs)        # top-left diagonal\n",
    "#     ax.plot((1 - d, 1 + d), (-d, +d), **kwargs)  # top-right diagonal\n",
    "\n",
    "#     kwargs.update(transform=ax2.transAxes)  # switch to the bottom axes\n",
    "#     ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)  # bottom-left diagonal\n",
    "#     ax2.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)  # bottom-right diagonal   \n",
    "#     ax2.legend(['max', 'avg', 'median'], loc='lower right')\n",
    "#     ax2.set_xticks(range(1, 17))\n",
    "#     ax2.set_xticklabels((1, 2, \"\", 4, \"\", \"\", \"\", 8, \"\", \"\", \"\", \"\", \"\", \"\", \"\", 16))\n",
    "#     ax2.set_xlabel(\"# child nodes\")\n",
    "#     f.text(0.0, 0.55, 'windows/s in 1000', ha='center', va='center', rotation='vertical')\n",
    "#     f.savefig(f\"/tmp/plots/root_tp.pdf\", bbox_inches=\"tight\")\n",
    "#     f.show()\n",
    "        \n",
    "    plt.legend()\n",
    "    str_child_streams = [str(cs) for cs in child_streams]\n",
    "#     plt.xticks(range(1, 17), (1, 2, \"\", 4, \"\", \"\", \"\", 8, \"\", \"\", \"\", \"\", \"\", \"\", \"\", 16))\n",
    "    plt.ylabel(\"events/s in mio.\")\n",
    "    plt.xlabel(\"# keys\")\n",
    "#     plt.title(title)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylim(ymin=0) #, ymax=5.5)\n",
    "    plt.savefig(f\"/tmp/plots/num_keys.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def group_throughput_mode(bms, num_child_streams):\n",
    "    groups = defaultdict(dict)\n",
    "    for benchmark, run_throughputs in bms:\n",
    "        group, agg_fn, mode = benchmark\n",
    "        group_key = (group, mode)\n",
    "        print(f\"Adding benchmark {benchmark} to group {group_key}\")\n",
    "        bm_throughputs = []\n",
    "        for num_cs in num_child_streams:\n",
    "            num_streams = num_cs[1] \n",
    "            throughput = run_throughputs[num_cs]\n",
    "            bm_throughputs.append((num_streams * throughput) / 1_000_000)\n",
    "#             bm_throughputs.append(throughput / 1_000_000)\n",
    "        groups[group_key][agg_fn] = bm_throughputs\n",
    "    return groups\n",
    "    \n",
    "def group_throughput_benchmarks(bms, num_child_streams):\n",
    "    all_groups = group_throughput_mode(sorted(bms.items()), num_child_streams)\n",
    "    \n",
    "    groups = {}\n",
    "    groups[\"distributed\"] = {run: tps for run, tps in all_groups.items() if run[1] == \"DISTRIBUTED\"}\n",
    "    groups[\"centralized\"] = {run: tps for run, tps in all_groups.items() if run[1] == \"SINGLE_NODE\"}\n",
    "    \n",
    "#     print(\"\\n\\n\")\n",
    "#     print(f\"NODE_CONFIG: {num_child_streams}\")\n",
    "#     print(\"\\nGROUPS:\")\n",
    "#     pprint.pprint(groups)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_throughput_benchmarks(bms, num_child_streams):\n",
    "    groups = group_throughput_benchmarks(bms, num_child_streams)\n",
    "    print(groups)\n",
    "    for mode, sub_groups in groups.items():\n",
    "        if mode != 'distributed': continue\n",
    "        for group, throughputs in sub_groups.items():\n",
    "            plot_throughput_group(num_child_streams, throughputs, group)\n",
    "        \n",
    "def plot_multi_child_throughputs(bms):\n",
    "    num_child_streams = [(1, 1), (2, 2), (4, 4), (8, 8)]  #, (16, 16)]\n",
    "    plot_throughput_benchmarks(bms, num_child_streams)\n",
    "    \n",
    "def plot_single_child_throughputs(bms):\n",
    "    num_child_streams = [(1, 1), (1, 2), (1, 4), (1, 8)]\n",
    "    plot_throughput_benchmarks(bms, num_child_streams)\n",
    "    \n",
    "def plot_num_keys(bms):\n",
    "    num_child_streams = [(1, 1), (1, 10), (1, 100), (1, 1000), (1, 10000), (1, 100000)]\n",
    "    plot_throughput_benchmarks(bms, num_child_streams)\n",
    "\n",
    "           \n",
    "# plot_single_child_throughputs(MATRIX_TP)\n",
    "# plot_multi_child_throughputs(MATRIX_TP)\n",
    "# plot_multi_child_throughputs(COUNT_TP)\n",
    "# plot_multi_child_throughputs(ROOT_TP)\n",
    "plot_num_keys(KEYS_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_both_scale(dist_avg, central_avg, dist_median, central_median):\n",
    "    markers = [\"x\", \"^\", \"o\"]\n",
    "    \n",
    "#     print(rcParams.keys())\n",
    "    font_size = 16\n",
    "    plt.rc('font', family='serif', serif='Times')\n",
    "    plt.rc('xtick', labelsize=font_size)\n",
    "    plt.rc('ytick', labelsize=font_size)\n",
    "    plt.rc('axes', labelsize=font_size)\n",
    "    plt.rc('figure', autolayout=False)\n",
    "    plt.rc('font', size=font_size)\n",
    "    plt.rc('lines', linewidth=4)\n",
    "    plt.rc('lines', markersize=8)\n",
    "    plt.rc('lines', markeredgewidth=2)\n",
    "    plt.style.use('seaborn-deep')\n",
    "    plt.rc('figure', figsize=(4.5, 3))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "#     plt_avg = fig.add_subplot(1, 2, 1)\n",
    "    plt_avg = fig.add_subplot(1, 1, 1)\n",
    "    plt_avg.plot([1, 2, 4, 8], dist_avg, marker=markers[0], ms=10)\n",
    "    plt_avg.plot([1, 2, 4, 8], central_avg, marker=markers[1])\n",
    "\n",
    "    plt_avg.set_xticks(range(1, 9))\n",
    "    plt_avg.set_ylabel(\"events/s in million\")\n",
    "    plt_avg.set_xlabel(\"# children\")\n",
    "    plt_avg.set_ylim(ymin=0, ymax=8)\n",
    "    \n",
    "#     plt_med = fig.add_subplot(1, 2, 2)\n",
    "#     plt_med = fig.add_subplot(1, 1, 1)\n",
    "#     plt_med.plot([1, 2, 4, 8], dist_median, marker=markers[0], label=f\"distributed\")\n",
    "#     plt_med.plot([1, 2, 4, 8], central_median, marker=markers[1], label=f\"centralized\")\n",
    "        \n",
    "#     plt_med.set_xticks(range(1, 9))\n",
    "# #     plt_med.set_ylabel(\"events/s in million\")\n",
    "#     plt_med.set_xlabel(\"# children\")\n",
    "#     plt_med.set_ylim(ymin=0, ymax=0.21)\n",
    "    \n",
    "    \n",
    "#     fig.legend([\"distributed\", \"centralized\"], fontsize=font_size, loc=\"upper center\", ncol=2)\n",
    "    plt.savefig(f\"/tmp/paper_plots/scale_avg.pdf\", bbox_inches=\"tight\")\n",
    "    fig.show()\n",
    "\n",
    "def plot_scale_throughput_benchmarks(bms, num_child_streams):\n",
    "    groups = group_throughput_benchmarks(bms, num_child_streams)\n",
    "    print(f\"groups: {groups['distributed'][('TUMBLING,1000', 'DISTRIBUTED')]}\")\n",
    "    dist_avg = groups['distributed'][('TUMBLING,1000', 'DISTRIBUTED')][\"M_AVG\"]\n",
    "    central_avg = groups['centralized'][('TUMBLING,1000', 'SINGLE_NODE')][\"M_AVG\"]\n",
    "    \n",
    "    dist_median = groups['distributed'][('TUMBLING,1000', 'DISTRIBUTED')][\"M_MEDIAN\"]\n",
    "    central_median = groups['centralized'][('TUMBLING,1000', 'SINGLE_NODE')][\"M_MEDIAN\"]\n",
    "#     dist_median = [x * 100000 for x  in dist_median]\n",
    "#     central_median = [x * 100000 for x in central_median]\n",
    "    plot_both_scale(dist_avg, central_avg, dist_median, central_median)\n",
    "    \n",
    "def plot_sessions(bms):\n",
    "    num_child_streams = [(1, 1), (2, 2), (4, 4), (8, 8)]\n",
    "    plot_scale_throughput_benchmarks(bms, num_child_streams)\n",
    "    \n",
    "plot_sessions(MATRIX_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "OUT_OF_ORDER = [0, 40.9, 61.3, 91.4]\n",
    "\n",
    "def plot_throughput_by_agg_fn(child_streams, throughputs):\n",
    "    print(throughputs)\n",
    "    formats = iter(FORMATS)\n",
    "    data = defaultdict(list)\n",
    "    for mode, run in sorted(throughputs):\n",
    "        for agg_fn, tps in run.items():\n",
    "            data[agg_fn].append(tps)\n",
    "\n",
    "    print(data)\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    for agg_fn, (dist, single) in data.items():\n",
    "        if agg_fn != \"MAX\": continue\n",
    "        ax1.plot([1, 2, 4, 8], dist, label=\"distributed max\", marker=\"o\", ms=7)\n",
    "        ax1.plot([1, 2, 4, 8], single, label=\"centralized max\", marker=\"^\", ms=8)\n",
    "        ax1.set_ylabel(\"events/s in mio.\")\n",
    "        ax1.set_xlabel(\"# input streams\")\n",
    "        ax1.set_ylim(ymin=0, ymax=1.1 * max(dist))\n",
    "        ax1.set_xlim(xmin=0.5)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot([1, 2, 4, 8], OUT_OF_ORDER, color=\"crimson\", ls=\"--\")\n",
    "    ax2.set_ylabel(\"% out-of-order events\")\n",
    "    ax2.set_ylim(ymin=0)\n",
    "    ax2.set_xlim(xmin=0.5)\n",
    "    ax2.set_xticks(range(1, 9))\n",
    "    ax2.set_xticklabels((1, 2, \"\", 4, \"\", \"\", \"\", 8))\n",
    "    \n",
    "    ax1.legend([\"distributed max\", \"centralized max\"], loc=\"center right\")\n",
    "    ax2.legend([\"out-of-orderness\"], loc=\"upper center\")\n",
    "    \n",
    "    fig.savefig(f\"/tmp/plots/count_scale.pdf\", bbox_inches=\"tight\")\n",
    "    fig.show()    \n",
    "\n",
    "#     for agg_fn, (dist, single) in data.items():\n",
    "#         if agg_fn != \"MAX\": continue\n",
    "#         plt.plot([1, 2, 4, 8], dist, label=\"distributed max\", marker=\"o\", ms=7)\n",
    "#         plt.plot([1, 2, 4, 8], single, label=\"centralized max\", marker=\"^\", ms=8)\n",
    "#         plt.plot([1, 2, 4, 8])\n",
    "#         plt.legend()\n",
    "#         plt.ylabel(\"events/s in mio.\")\n",
    "#         plt.xlabel(\"# input streams\")\n",
    "#         plt.ylim(ymin=0, ymax=1.1 * max(dist))\n",
    "#         plt.xlim(xmin=0.5)\n",
    "# #         plt.savefig(f\"/tmp/plots/count_scale_{agg_fn}.pdf\", bbox_inches=\"tight\")\n",
    "#         plt.show()\n",
    "\n",
    "def plot_tumbling_scale(bms):\n",
    "    num_child_streams = [(1, 1), (2, 2), (4, 4), (8, 8)]\n",
    "    groups = group_throughput_benchmarks(bms, num_child_streams)\n",
    "    groups = [(bm[1], tps) for mode, g in groups.items() for bm, tps in g.items() if bm[0].startswith(\"TUMBLING\")]\n",
    "    plot_throughput_by_agg_fn(num_child_streams, groups)\n",
    "    \n",
    "def plot_tumbling_single_node(bms):\n",
    "    num_child_streams = [(1, 1), (1, 2), (1, 4), (1, 8)]\n",
    "    groups = group_throughput_benchmarks(bms, num_child_streams)\n",
    "    groups = [(bm[1], tps) for mode, g in groups.items() for bm, tps in g.items() if bm[0].startswith(\"TUMBLING\")]\n",
    "    plot_throughput_by_agg_fn(num_child_streams, groups)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# plot_tumbling_scale(MATRIX_TP)\n",
    "# plot_tumbling_single_node(MATRIX_TP)\n",
    "plot_tumbling_scale(COUNT_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_concurrent_throughput_group(num_windows, throughputs):\n",
    "    markers = iter(['o', '^', 'x', '*'])\n",
    "    print(throughputs)\n",
    "    for (agg_fn, mode), tps in sorted(throughputs):\n",
    "        if agg_fn == \"M_MEDIAN\": continue\n",
    "        mode_str = \"distributed\" if mode == \"DISTRIBUTED\" else \"centralized\"\n",
    "        plt.plot(num_windows, tps, marker=next(markers), ms=8, label=f\"{mode_str} - {agg_fn.replace('M_', '').lower()}\")\n",
    "\n",
    "    plt.ylabel(\"events/s in mio.\")\n",
    "    plt.xlabel(\"# concurrent windows\")\n",
    "    plt.legend()\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.savefig(f\"/tmp/plots/concurrent_decomposable.png\", bbox_inches=\"tight\")\n",
    "    plt.savefig(f\"/tmp/plots/concurrent_decomposable.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "bm_throughputs = defaultdict(list)\n",
    "bm_num_windows = set()\n",
    "for benchmark, run_throughputs in sorted(CONCURRENT_TP.items(), key=lambda x: int(x[0][0].split(\",\")[1])):\n",
    "    print(f\"Benchmark {benchmark}\")\n",
    "    num_windows = int(benchmark[0].split(\",\")[1])\n",
    "    bm_num_windows.add(num_windows)\n",
    "    agg_fn = benchmark[1]\n",
    "    mode = benchmark[2]\n",
    "    for throughput in run_throughputs.values(): \n",
    "        bm_throughputs[(agg_fn, mode)].append(throughput / 1_000_000)\n",
    "\n",
    "# print(bm_throughputs)\n",
    "\n",
    "plot_concurrent_throughput_group(sorted(bm_num_windows), bm_throughputs.items())\n",
    "\n",
    "# for (agg_fn, mode), tps in sorted(bm_throughputs.items()):\n",
    "#     plot_concurrent_throughput_group(sorted(bm_num_windows), (agg_fn.replace('M_', '').lower(), mode, tps), f\"{agg_fn.replace('M_', '')} - {mode}\")\n",
    "    # plt.savefig(f\"/tmp/plots/concurrent_max_tumbling.png\")\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_both_sessions(child_streams, dist, central):\n",
    "    markers = iter([\"x\", \"^\", \"o\"])   \n",
    "    print(dist)\n",
    "    print(central)\n",
    "\n",
    "    plt.plot(dist, marker=next(markers), label=\"distributed max\")\n",
    "    plt.plot(central, marker=next(markers), label=\"centralized max\")\n",
    "        \n",
    "    plt.legend()\n",
    "    str_child_streams = [str(cs) for cs in child_streams]\n",
    "    plt.xticks(range(3), (\"2 (3)\", \"3 (7)\", \"4 (15)\"))\n",
    "    plt.ylabel(\"events/s in mio.\")\n",
    "    plt.xlabel(\"height of balanced tree (# total nodes)\")\n",
    "    plt.ylim(ymin=0) #, ymax=5.5)\n",
    "    plt.savefig(f\"/tmp/plots/session_tp.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_session_throughput_benchmarks(bms, num_child_streams):\n",
    "    groups = group_throughput_benchmarks(bms, num_child_streams)\n",
    "    print(groups)\n",
    "    dist = list(groups['distributed'].values())[0][\"MAX\"]\n",
    "    central = list(groups['centralized'].values())[0][\"MAX\"]\n",
    "    plot_both_sessions(num_child_streams, dist, central)\n",
    "    \n",
    "def plot_sessions(bms):\n",
    "    num_child_streams = [(2, 2), (4, 4), (8, 8)]\n",
    "    plot_session_throughput_benchmarks(bms, num_child_streams)\n",
    "    \n",
    "plot_sessions(SESSION_TP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
