{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "RUN_RE = re.compile(r\"Running ((.*) intermediates, )?(\\d+) child.*, (\\d+) stream.*\")\n",
    "THROUGHPUT_RE = re.compile(r\"Found sustainable candidate \\((\\d+) events/s.\\)*\")\n",
    "BENCHMARK_RE = re.compile(r\"BENCHMARK: WINDOWS: (.*) - AGG_FNS: (.*)\")\n",
    "\n",
    "def parse_log_file(log_file):\n",
    "    sustainable_throughputs = {}\n",
    "    \n",
    "    current_bm = None\n",
    "    current_run = None\n",
    "    current_throughput = None\n",
    "    with open(log_file) as f:\n",
    "        for line in f:\n",
    "            benchmark_match = BENCHMARK_RE.match(line)\n",
    "            if benchmark_match is not None:\n",
    "                curr_windows, curr_agg_fn = benchmark_match.group(1), benchmark_match.group(2)\n",
    "                if \"-\" in curr_agg_fn:\n",
    "                    hyphen_pos = curr_agg_fn.find(\"-\")\n",
    "                    curr_agg_fn = curr_agg_fn[:hyphen_pos - 1]\n",
    "                current_bm = (curr_windows, curr_agg_fn)\n",
    "                sustainable_throughputs[current_bm] = {}\n",
    "                current_throughput = None\n",
    "                # print(current_bm)\n",
    "            \n",
    "            run_match = RUN_RE.match(line)\n",
    "            if run_match is not None:\n",
    "                if current_run != None:\n",
    "                    print(f\"Did not find candidate line for {current_run}\")\n",
    "                current_run = (int(run_match.group(3)), int(run_match.group(4)))\n",
    "                current_throughput = None\n",
    "                # print(current_run)\n",
    "\n",
    "            throughput_match = THROUGHPUT_RE.match(line)\n",
    "            if throughput_match is not None:\n",
    "                if current_throughput is not None:\n",
    "                    print(f\"Did not find run line after {current_run}\")\n",
    "                current_throughput = int(throughput_match.group(1))\n",
    "                sustainable_throughputs[current_bm][current_run] = current_throughput\n",
    "                current_run = None\n",
    "                \n",
    "    if current_run is not None:\n",
    "        print(f\"Did not find candidate line for {current_run}\")\n",
    "                \n",
    "    return sustainable_throughputs\n",
    "                \n",
    "def get_all_throughputs(log_path):\n",
    "    all_throughputs = defaultdict(dict)\n",
    "    for log_file in sorted(os.listdir(log_path)):\n",
    "        if log_file.endswith(\".log\"):\n",
    "            print(f\"Parsing {log_file}\")\n",
    "            sustainable_throughputs = parse_log_file(os.path.join(log_path, log_file))\n",
    "#             print(f\"current: {sustainable_throughputs}\")\n",
    "            for bm, tps in sustainable_throughputs.items():\n",
    "                all_throughputs[bm].update(tps)\n",
    "#             print(f\"all:     {all_throughputs}\\n\")\n",
    "    return all_throughputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BASE_LOG_DIR = \"/Users/law/repos/ma/benchmark-runs\"\n",
    "\n",
    "def merge_paths(paths):\n",
    "    merged_tp = defaultdict(dict)\n",
    "    for path in paths:\n",
    "        abs_path = os.path.join(BASE_LOG_DIR, path)\n",
    "        tp = get_all_throughputs(abs_path)\n",
    "        for bm, tps in tp.items():\n",
    "            merged_tp[bm].update(tps)\n",
    "    pprint.pprint(merged_tp)\n",
    "    return merged_tp\n",
    "\n",
    "print(\"CONCURRENT\")\n",
    "CONCURRENT_PATHS = [\n",
    "    \"concurrent_partial\",\n",
    "    \"concurrent_rest\",\n",
    "    \"concurrent_tumbling\",\n",
    "    \"concurrent_tumbling_high_bad\",\n",
    "]\n",
    "CONCURRENT_TP = merge_paths(CONCURRENT_PATHS)\n",
    " \n",
    "print(\"DISTRIBUTED MATRIX\")\n",
    "DIST_MATRIX_PATHS = [\n",
    "    \"matrix_dist_all\"\n",
    "]\n",
    "DIST_MATRIX_TP = merge_paths(DIST_MATRIX_PATHS)\n",
    "\n",
    "print(\"SINGLE NODE MATRIX\")\n",
    "SINGLE_MATRIX_PATHS = [\n",
    "    \"matrix_single_all\",\n",
    "]\n",
    "SINGLE_MATRIX_TP = merge_paths(SINGLE_MATRIX_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_throughputs(all_throughputs):\n",
    "    for benchmark, run_throughputs in sorted(all_throughputs.items()):\n",
    "        print(f\"Benchmark {benchmark}\")\n",
    "        for (num_children, num_streams), throughput in sorted(run_throughputs.items()):\n",
    "            print(f\"Total sustainable throughput for {num_children} child(ren) with \" \\\n",
    "                  f\"{num_streams // num_children} stream(s) each \" \\\n",
    "                  f\"is {(throughput * num_streams // num_children): >7d} events/s per child.\")\n",
    "        print()\n",
    "    \n",
    "\n",
    "print_throughputs(CONCURRENT_TP)\n",
    "print_throughputs(DIST_MATRIX_TP)\n",
    "print_throughputs(SINGLE_MATRIX_TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "rcParams.update({'figure.autolayout': True, 'pgf.rcfonts' : False})\n",
    "FORMATS = [\"b-o\", \"g-x\", \"r-^\", \"c-<\", \"m-+\", \"k-*\",]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Sustainable Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_throughput_group(child_streams, throughputs, title):\n",
    "    formats = iter(FORMATS)\n",
    "    sorted_throughputs = sorted(throughputs.items())\n",
    "    # print(f\"sorted_tps: {sorted_throughputs}\")\n",
    "    for agg_fn, tp in sorted_throughputs:\n",
    "        plt.plot(tp, next(formats), label=agg_fn)\n",
    "        \n",
    "    plt.legend()\n",
    "    str_child_streams = [str(cs) for cs in child_streams]\n",
    "    plt.xticks(range(len(child_streams)), str_child_streams)\n",
    "    plt.ylabel(\"events/s in mio.\")\n",
    "    plt.xlabel(\"#children, # streams\")\n",
    "    plt.title(title)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.show()\n",
    "#     plt.savefig(f\"/tmp/plots/single_child_{title[0].replace(',', '_')}_{title[1]}.png\")\n",
    "#     plt.close()\n",
    "\n",
    "def group_throughput_mode(bms, num_child_streams):\n",
    "    groups = defaultdict(dict)\n",
    "    for benchmark, run_throughputs in bms:\n",
    "        group, agg_fn = benchmark\n",
    "        print(f\"Adding benchmark {benchmark} to group {group}\")\n",
    "        bm_throughputs = []\n",
    "        for num_cs in num_child_streams:\n",
    "            num_streams = num_cs[1] \n",
    "            throughput = run_throughputs[num_cs]\n",
    "            bm_throughputs.append((num_streams * throughput) / 1_000_000)\n",
    "        groups[group][agg_fn] = bm_throughputs\n",
    "    return groups\n",
    "    \n",
    "def group_throughput_benchmarks(dist_bms, single_bms, num_child_streams):\n",
    "    groups = {}\n",
    "    groups[\"distributed\"] = group_throughput_mode(sorted(dist_bms.items()), num_child_streams)\n",
    "    groups[\"centralized\"] = group_throughput_mode(sorted(single_bms.items()), num_child_streams)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"NODE_CONFIG: {num_child_streams}\")\n",
    "    print(\"\\nGROUPS:\")\n",
    "    pprint.pprint(groups)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_throuput_benchmarks(dist_bms, single_bms, num_child_streams):\n",
    "    groups = group_throughput_benchmarks(dist_bms, single_bms, num_child_streams)\n",
    "    for mode, sub_groups in groups.items():\n",
    "        for group, throughputs in sub_groups.items():\n",
    "            plot_throughput_group(num_child_streams, throughputs, group)\n",
    "        \n",
    "def plot_multi_child_throughputs(dist_bms, single_bms):\n",
    "    num_child_streams = [(1, 1), (2, 2), (4, 4), (8, 8)]\n",
    "    plot_throuput_benchmarks(dist_bms, single_bms, num_child_streams)\n",
    "    \n",
    "def plot_single_child_throughputs(dist_bms, single_bms):\n",
    "    num_child_streams = [(1, 1), (1, 2), (1, 4), (1, 8)]\n",
    "    plot_throuput_benchmarks(dist_bms, single_bms, num_child_streams)\n",
    "\n",
    "           \n",
    "plot_single_child_throughputs(DIST_MATRIX_TP, SINGLE_MATRIX_TP)\n",
    "plot_multi_child_throughputs(DIST_MATRIX_TP, SINGLE_MATRIX_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_concurrent_throughput_group(num_windows, throughputs, title):\n",
    "    plt.plot(num_windows, throughputs)\n",
    "    plt.ylabel(\"events/s in mio.\")\n",
    "    plt.xlabel(\"#concurrent windows\")\n",
    "    plt.title(title)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"/tmp/plots/single_child_{title[0].replace(',', '_')}_{title[1]}.png\")\n",
    "    # plt.close()\n",
    "    \n",
    "bm_throughputs = defaultdict(list)\n",
    "bm_num_windows = set()\n",
    "for benchmark, run_throughputs in sorted(CONCURRENT_TP.items(), key=lambda x: int(x[0][0].split(\",\")[1])):\n",
    "    print(f\"Benchmark {benchmark}\")\n",
    "    num_windows = int(benchmark[0].split(\",\")[1])\n",
    "    bm_num_windows.add(num_windows)\n",
    "    agg_fn = benchmark[1]\n",
    "    for throughput in run_throughputs.values(): \n",
    "        bm_throughputs[agg_fn].append(throughput / 1_000_000)\n",
    "\n",
    "print(bm_throughputs)\n",
    "\n",
    "for agg_fn, tps in sorted(bm_throughputs.items()):\n",
    "    plot_concurrent_throughput_group(sorted(bm_num_windows)[:7], bm_throughputs[agg_fn][:7], agg_fn.replace('M_', ''))\n",
    "    # plt.savefig(f\"/tmp/plots/concurrent_max_tumbling.png\")\n",
    "    # plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
