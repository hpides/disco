{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tempfile\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "BENCHMARK_RE = re.compile(r\"BENCHMARK: WINDOWS: (.*) - AGG_FNS: (.*) - (DISTRIBUTED|SINGLE_NODE)\")\n",
    "RUN_RE = re.compile(r\"Running ((.*) intermediates, )?(\\d+) child.*, (\\d+) stream.*\")\n",
    "LOGS_RE = re.compile(r\"Writing logs to (.*)\")\n",
    "DATA_SIZE_RE = re.compile(r\"Data size:\\s+(\\d+) bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_file(capture_zip):\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    print(f\"Extracting to {temp_dir}\")\n",
    "    with zipfile.ZipFile(capture_zip) as zf:\n",
    "        zf.extractall(temp_dir)\n",
    "        \n",
    "    capture_file = os.path.join(temp_dir, \"network_capture.pcap\")\n",
    "    print(f\"Analyzing {capture_file}\")\n",
    "    analyzer = subprocess.run((\"capinfos\", \"-csdizyxuM\", capture_file), timeout=120, capture_output=True, text=True)\n",
    "\n",
    "    print(f\"Deleting {capture_file}\")\n",
    "    os.remove(capture_file)\n",
    "    return analyzer.stdout\n",
    "\n",
    "def analyze_capture_files(log_file):\n",
    "    temp_out_file_name = f\"{log_file}.temp\"\n",
    "    with open(temp_out_file_name, \"w\") as out_f:\n",
    "        with open(log_file) as f:\n",
    "            for line in f:\n",
    "                bm_match = BENCHMARK_RE.match(line)\n",
    "                if bm_match is not None:\n",
    "                    out_f.write(line)\n",
    "\n",
    "                run_match = RUN_RE.match(line)\n",
    "                if run_match is not None:\n",
    "                    out_f.write(line)\n",
    "\n",
    "                logs_match = LOGS_RE.match(line)\n",
    "                if logs_match is not None:\n",
    "                    analysis_lines = analyze_file(os.path.join(logs_match.group(1), \"network_capture.zip\"))\n",
    "                    out_f.write(analysis_lines)\n",
    "    print(f\"Moving {log_file} to {log_file}.backup\")\n",
    "    shutil.move(log_file, f\"{log_file}.backup\")\n",
    "    print(f\"Moving {temp_out_file_name} to {log_file}\")\n",
    "    shutil.move(temp_out_file_name, log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_sizes(log_file):\n",
    "    current_bm = (None, None, None)\n",
    "    data_sizes = defaultdict(dict)\n",
    "    with open(log_file) as f:\n",
    "        for line in f:\n",
    "            bm_match = BENCHMARK_RE.match(line)\n",
    "            if bm_match is not None:\n",
    "                current_bm = (bm_match.group(1), bm_match.group(2), bm_match.group(3))\n",
    "                continue\n",
    "                \n",
    "            run_match = RUN_RE.match(line)\n",
    "            if run_match is not None:\n",
    "                current_run = (run_match.group(2), int(run_match.group(3)), int(run_match.group(4))) \n",
    "                continue\n",
    "                \n",
    "            data_match = DATA_SIZE_RE.match(line)\n",
    "            if data_match is not None:\n",
    "                data_size = int(data_match.group(1))\n",
    "                data_sizes[current_bm][current_run] = data_size\n",
    "                continue\n",
    "            \n",
    "    return data_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_all_network_sizes(log_files):\n",
    "    network_sizes = defaultdict(dict)\n",
    "    for log_file in log_files:\n",
    "        print(f\"Analyzing {log_file}\")\n",
    "        sizes = get_network_sizes(log_file)\n",
    "        for bm, runs in sizes.items():\n",
    "            network_sizes[bm].update(runs)\n",
    "            \n",
    "    return network_sizes\n",
    "\n",
    "LOG_DIR = \"/Users/law/repos/ma/local_bm_runs\"\n",
    "LOG_FILE_1 = f\"{LOG_DIR}/network_bm_2019_10_01_1011.log\"\n",
    "LOG_FILE_2 = f\"{LOG_DIR}/network_bm_2019_10_01_1255.log\"\n",
    "LOG_FILE_3 = f\"{LOG_DIR}/network_bm_2019_10_03_1355.log\"\n",
    "NETWORK_SIZES = get_all_network_sizes([LOG_FILE_1, LOG_FILE_2, LOG_FILE_3])\n",
    "pprint(NETWORK_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ALL_SIZES = []\n",
    "\n",
    "for setup, runs in NETWORK_SIZES.items():\n",
    "    for node_config, network_size in runs.items():\n",
    "        print(f\"{setup}, {node_config}\")\n",
    "        size_in_mb = int(network_size / (1024 * 1024))\n",
    "        print(f\"Total bytes sent through network: {size_in_mb} MB.\")\n",
    "        ALL_SIZES.append((size_in_mb, setup, node_config))\n",
    "        \n",
    "ALL_SIZES.sort(reverse=True)\n",
    "print(ALL_SIZES[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "rcParams.update({'figure.autolayout': True, 'pgf.rcfonts' : False, 'font.size': 14})\n",
    "plt.style.use('seaborn-deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_network(sizes, bm):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_tight_layout(False)\n",
    "    \n",
    "    font_size = 16\n",
    "    plt.rc('font', family='serif', serif='Times')\n",
    "    plt.rc('xtick', labelsize=font_size)\n",
    "    plt.rc('ytick', labelsize=font_size)\n",
    "    plt.rc('axes', labelsize=font_size)\n",
    "    plt.rc('figure', autolayout=False)\n",
    "    plt.rc('font', size=font_size)\n",
    "    plt.rc('lines', linewidth=4)\n",
    "    plt.rc('lines', markersize=8)\n",
    "    plt.rc('lines', markeredgewidth=2)\n",
    "    plt.style.use('seaborn-deep')\n",
    "    plt.rc('figure', figsize=(4.5, 3))\n",
    "\n",
    "    \n",
    "    bar_width = 0.40\n",
    "    assert len(sizes) % 2 == 0\n",
    "    x_locations = list(range(len(sizes) // 2))\n",
    "    \n",
    "    clean_sizes = [(s[0], s[1][2], s[2]) for s in sizes]\n",
    "    single_sizes = sorted([s for s in clean_sizes if s[1] == \"SINGLE_NODE\"], key=lambda s: s[2])\n",
    "    dist_sizes = sorted([s for s in clean_sizes if s[1] == \"DISTRIBUTED\"], key=lambda s: s[2])\n",
    "    print(single_sizes, dist_sizes)\n",
    "    assert len(single_sizes) == len(dist_sizes)\n",
    "    node_configs = [s[2] for s in single_sizes]\n",
    "    \n",
    "    single_sizes_only = [s[0] / 1024 * 10 for s in single_sizes]\n",
    "    dist_sizes_only = [s[0] / 1024 * 10 for s in dist_sizes]\n",
    "    print(single_sizes_only, dist_sizes_only)\n",
    "    \n",
    "    ax.bar(x_locations, dist_sizes_only, bar_width, bottom=0, label=\"distributed\", hatch=\"//\")\n",
    "\n",
    "    single_x_locations = [x + (bar_width) for x in x_locations]\n",
    "    ax.bar(single_x_locations, single_sizes_only, bar_width, bottom=0, label=\"centralized\", hatch=\"\\\\\\\\\")\n",
    "\n",
    "#     ax.set_title(bm)\n",
    "    ax.set_ylabel(\"# bytes sent in GB\")\n",
    "    ax.set_xlabel(\"height of network tree\")\n",
    "    ax.set_xticks([x + (bar_width / 2) for x in x_locations])\n",
    "    ax.set_xticklabels([str(nc).count(\"1\") for nc in node_configs])\n",
    "    ax.set_yticks(range(0, 14))\n",
    "    ax.set_yticklabels((\"0\", \"\", \"2\", \"\", \"4\", \"\", \"6\", \"\", \"8\", \"\", \"10\", \"\", \"12\"))\n",
    "    ax.set_ylim(ymin=0, ymax=13)\n",
    "#     ax.set_xticklabels(node_configs)\n",
    "#     plt.legend()\n",
    "    plt.savefig(f\"/tmp/paper_plots/network_{bm}.pdf\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.show()\n",
    "\n",
    "chain_config = [('0', 1, 1), ('1', 1, 1), ('1-1', 1, 1), ('1-1-1', 1, 1)]\n",
    "num_child_config = [('0', 1, 1), ('0', 2, 2), ('0', 4, 4), ('0', 8, 8)]\n",
    "multi_level_config = [('2', 4, 4), ('3', 6, 6), ('4', 8, 8), ('2-4', 8, 8), ('4-8', 16, 16)]\n",
    "\n",
    "node_configs = [\n",
    "    chain_config, \n",
    "#     num_child_config,\n",
    "#     multi_level_config\n",
    "]\n",
    "\n",
    "bms = set()\n",
    "for size in ALL_SIZES:\n",
    "    bms.add(size[1][0])\n",
    "\n",
    "# for bm in bms:\n",
    "for agg_fn in [\"MAX\", \"M_AVG\", \"M_MEDIAN\"]:\n",
    "    for node_config in node_configs:\n",
    "        bm_sizes = [size for size in ALL_SIZES if size[1][0] == \"TUMBLING,1000\" \\\n",
    "                                                and size[1][1] == agg_fn \\\n",
    "                                                and size[2] in node_config]\n",
    "#         plot_network(bm_sizes, f\"{bm} : {agg_fn}\")\n",
    "        if agg_fn != \"M_MEDIAN\": continue \n",
    "        plot_network(bm_sizes, f\"{agg_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
